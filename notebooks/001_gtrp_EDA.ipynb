{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (2.23.2)\n",
      "Requirement already satisfied: google-auth-oauthlib in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: google-cloud-bigquery in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (3.11.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-auth) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-auth) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-auth-oauthlib) (1.3.1)\n",
      "Requirement already satisfied: httplib2>=0.19.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-auth-httplib2) (0.22.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (1.59.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (2.12.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (1.22.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (2.6.0)\n",
      "Requirement already satisfied: packaging>=20.0.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (23.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (4.24.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-cloud-bigquery) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.59.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.5.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2023.7.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\cursos\\fiap_pós\\gp27_techchallenge_3\\.venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-auth google-auth-oauthlib google-auth-httplib2 google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > ..//requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _spark import *\n",
    "from transformations import transform\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "spark = get_spark()\n",
    "\n",
    "gcs_bucket =  'tech-challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark\\\n",
    "    .read\\\n",
    "    .option('delimiter',',')\\\n",
    "    .option('header',True)\\\n",
    "    .option('inferSchema',True)\\\n",
    "    .csv('../data/raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigQuery links\n",
    "\n",
    "- [BigQuery Table](https://console.cloud.google.com/bigquery?hl=pt-br&project=fiap-tech-challenge-3&ws=!1m0)\n",
    "- [Storage](https://console.cloud.google.com/storage/browser/tech-challenge;tab=configuration?hl=pt-br&project=fiap-tech-challenge-3&prefix=&forceOnObjectsSortingFiltering=false)\n",
    "- [IAM e admin](https://console.cloud.google.com/iam-admin/iam?hl=pt-br&project=fiap-tech-challenge-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data\n",
    "\n",
    "#### Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a PySpark DataFrame to a BigQuery table\n",
    "\n",
    "df.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_f_covid_2020\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('uf', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_uf = spark.createDataFrame(data=[\n",
    "    {\n",
    "        \"11\": \"Rondônia\",\n",
    "        \"12\": \"Acre\",\n",
    "        \"13\": \"Amazonas\",\n",
    "        \"14\": \"Roraima\",\n",
    "        \"15\": \"Pará\",\n",
    "        \"16\": \"Amapá\",\n",
    "        \"17\": \"Tocantins\",\n",
    "        \"21\": \"Maranhão\",\n",
    "        \"22\": \"Piauí\",\n",
    "        \"23\": \"Ceará\",\n",
    "        \"24\": \"Rio Grande do Norte\",\n",
    "        \"25\": \"Paraíba\",\n",
    "        \"26\": \"Pernambuco\",\n",
    "        \"27\": \"Alagoas\",\n",
    "        \"28\": \"Sergipe\",\n",
    "        \"29\": \"Bahia\",\n",
    "        \"31\": \"Minas Gerais\",\n",
    "        \"32\": \"Espírito Santo\",\n",
    "        \"33\": \"Rio de Janeiro\",\n",
    "        \"35\": \"São Paulo\",\n",
    "        \"41\": \"Paraná\",\n",
    "        \"42\": \"Santa Catarina\",\n",
    "        \"43\": \"Rio Grande do Sul\",\n",
    "        \"50\": \"Mato Grosso do Sul\",\n",
    "        \"51\": \"Mato Grosso\",\n",
    "        \"52\": \"Goiás\",\n",
    "        \"53\": \"Distrito Federal\",\n",
    "    }], schema=_schema)\n",
    "\n",
    "_uf.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_uf\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('area_domicilio', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_area_domicilio = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Urbana',\n",
    "        '2': 'Rural',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_area_domicilio.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_area_domicilio\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('sexo', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_sexo = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Masculino',\n",
    "        '2': 'Feminino',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_sexo.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_sexo\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('raca', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_raca = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Branca',\n",
    "        '2': 'Preta',\n",
    "        '3': 'Amarela',\n",
    "        '4': 'Parda',\n",
    "        '5': 'Indígena',\n",
    "        '9': 'Ignorado',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_raca.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_raca\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('escolaridade', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_escolaridade = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Sem instrução',\n",
    "        '2': 'Fundamental incompleto',\n",
    "        '3': 'Fundamental completa',\n",
    "        '4': 'Médio incompleto',\n",
    "        '5': 'Médio completo',\n",
    "        '6': 'Superior incompleto',\n",
    "        '7': 'Superior completo',\n",
    "        '8': 'Pós-graduação, mestrado ou doutorado',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_escolaridade.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_escolaridade\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('escolaridade', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_resposta_covid = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Sim',\n",
    "        '2': 'Não ',\n",
    "        '3': 'Não sabe',\n",
    "        '9': 'Ignorado',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_resposta_covid.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_resposta_covid\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('resposta_internado', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_resposta_internado = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Sim',\n",
    "        '2': 'Não ',\n",
    "        '3': 'Não foi atendido',\n",
    "        '9': 'Ignorado',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_resposta_internado.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_resposta_internado\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('resposta_faixa_rendimento', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_resposta_faixa_rendimento = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '00':   '0 - 100',\n",
    "        '01':\t'101 - 300',\n",
    "        '02':\t'301 - 600',\n",
    "        '03':\t'601 - 800',\n",
    "        '04':\t'801 - 1.600',\n",
    "        '05':\t'1.601 - 3.000',\n",
    "        '06':\t'3.001 - 10.000',\n",
    "        '07':\t'10.001 - 50.000',\n",
    "        '08':\t'50.001 - 100.000',\n",
    "        '09':\t'Mais de 100.000',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_resposta_faixa_rendimento.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_resposta_faixa_rendimento\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('resposta_situacao_domicilio', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_resposta_situacao_domicilio = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Próprio - já pago ',\n",
    "        '2': 'Próprio - ainda pagando',\n",
    "        '3': 'Alugado',\n",
    "        '4': 'Cedido por empregador',\n",
    "        '5': 'Cedido por familiar ',\n",
    "        '6': 'Cedido de outra forma ',\n",
    "        '7': 'Outra condição',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_resposta_situacao_domicilio.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_resposta_situacao_domicilio\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('questao', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_mapa_questoes = spark.createDataFrame(data=[{  \n",
    "    \"UF\": \"uf\"\n",
    "  , \"V1012\": \"semana_mes\"\n",
    "  , \"V1013\": \"mes\"\n",
    "  , \"V1022\": \"area_domicilio\"\n",
    "  , \"A002\": \"idade\"\n",
    "  , \"A003\": \"sexo\"\n",
    "  , \"A004\": \"cor_raca\"\n",
    "  , \"A005\": \"escolaridade\"\n",
    "  , \"B0011\": \"teve_febre\"\n",
    "  , \"B0014\": \"teve_dificuldade_respirar\"\n",
    "  , \"B0015\": \"teve_dor_cabeca\"\n",
    "  , \"B0019\": \"teve_fadiga\"\n",
    "  , \"B00111\": \"teve_perda_cheiro\"\n",
    "  , \"B002\": \"foi_posto_saude\"\n",
    "  , \"B0031\": \"ficou_em_casa\"\n",
    "  , \"B005\": \"ficou_internado\"\n",
    "  , \"B007\": \"tem_plano_saude\"\n",
    "  , \"C007B\": \"assalariado\"\n",
    "  , \"C01011\": \"faixa_rendimento\"\n",
    "  , \"F001\": \"situacao_domicilio\"\n",
    "  }], schema=_schema)\n",
    "\n",
    "_mapa_questoes.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_questoes\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('sexo', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_sexo = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Masculino',\n",
    "        '2': 'Feminino',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_sexo.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'raw_pnad')\\\n",
    "    .option(\"table\", \"tb_d_sexo\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refined Data\n",
    "\n",
    "#### Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark\\\n",
    "    .read\\\n",
    "    .option('delimiter',',')\\\n",
    "    .option('header',True)\\\n",
    "    .option('inferSchema',True)\\\n",
    "    .csv('../data/raw')\n",
    "\n",
    "columns = [\n",
    "    \"UF\", \"V1012\", \"V1013\", \"V1022\", \"A002\", \"A003\",\n",
    "    \"A004\", \"A005\", \"B0011\", \"B0014\", \"B0015\", \"B0019\",\n",
    "    \"B00111\", \"B002\", \"B0031\", \"B005\", \"B007\", \"C007B\",\n",
    "    \"C01011\", \"F001\",'B009B'\n",
    "]\n",
    "\n",
    "df = df.select(columns)\n",
    "\n",
    "df = df\\\n",
    "        .withColumnRenamed(\"UF\", \"uf\")\\\n",
    "        .withColumnRenamed(\"V1012\", \"semana_mes\")\\\n",
    "        .withColumnRenamed(\"V1013\", \"mes\")\\\n",
    "        .withColumnRenamed(\"V1022\", \"area_domicilio\")\\\n",
    "        .withColumnRenamed(\"A002\", \"idade\")\\\n",
    "        .withColumnRenamed(\"A003\", \"sexo\")\\\n",
    "        .withColumnRenamed(\"A004\", \"cor_raca\")\\\n",
    "        .withColumnRenamed(\"A005\", \"escolaridade\")\\\n",
    "        .withColumnRenamed(\"B0011\", \"teve_febre\")\\\n",
    "        .withColumnRenamed(\"B0014\", \"teve_dificuldade_respirar\")\\\n",
    "        .withColumnRenamed(\"B0015\", \"teve_dor_cabeca\")\\\n",
    "        .withColumnRenamed(\"B0019\", \"teve_fadiga\")\\\n",
    "        .withColumnRenamed(\"B00111\", \"teve_perda_cheiro\")\\\n",
    "        .withColumnRenamed(\"B002\", \"foi_posto_saude\")\\\n",
    "        .withColumnRenamed(\"B0031\", \"ficou_em_casa\")\\\n",
    "        .withColumnRenamed(\"B005\", \"ficou_internado\")\\\n",
    "        .withColumnRenamed(\"B009B\", \"resultado_covid\")\\\n",
    "        .withColumnRenamed(\"B007\", \"tem_plano_saude\")\\\n",
    "        .withColumnRenamed(\"C007B\", \"assalariado\")\\\n",
    "        .withColumnRenamed(\"C01011\", \"faixa_rendimento\")\\\n",
    "        .withColumnRenamed(\"F001\", \"situacao_domicilio\")\n",
    "\n",
    "df.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_f_covid_2020\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('uf', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_uf = spark.createDataFrame(data=[\n",
    "    {\n",
    "        \"11\": \"Rondônia\",\n",
    "        \"12\": \"Acre\",\n",
    "        \"13\": \"Amazonas\",\n",
    "        \"14\": \"Roraima\",\n",
    "        \"15\": \"Pará\",\n",
    "        \"16\": \"Amapá\",\n",
    "        \"17\": \"Tocantins\",\n",
    "        \"21\": \"Maranhão\",\n",
    "        \"22\": \"Piauí\",\n",
    "        \"23\": \"Ceará\",\n",
    "        \"24\": \"Rio Grande do Norte\",\n",
    "        \"25\": \"Paraíba\",\n",
    "        \"26\": \"Pernambuco\",\n",
    "        \"27\": \"Alagoas\",\n",
    "        \"28\": \"Sergipe\",\n",
    "        \"29\": \"Bahia\",\n",
    "        \"31\": \"Minas Gerais\",\n",
    "        \"32\": \"Espírito Santo\",\n",
    "        \"33\": \"Rio de Janeiro\",\n",
    "        \"35\": \"São Paulo\",\n",
    "        \"41\": \"Paraná\",\n",
    "        \"42\": \"Santa Catarina\",\n",
    "        \"43\": \"Rio Grande do Sul\",\n",
    "        \"50\": \"Mato Grosso do Sul\",\n",
    "        \"51\": \"Mato Grosso\",\n",
    "        \"52\": \"Goiás\",\n",
    "        \"53\": \"Distrito Federal\",\n",
    "    }], schema=_schema)\n",
    "\n",
    "_uf.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_uf\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('area_domicilio', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_area_domicilio = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Urbana',\n",
    "        '2': 'Rural',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_area_domicilio.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_area_domicilio\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('sexo', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_sexo = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Masculino',\n",
    "        '2': 'Feminino',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_sexo.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_sexo\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('raca', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_raca = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Branca',\n",
    "        '2': 'Preta',\n",
    "        '3': 'Amarela',\n",
    "        '4': 'Parda',\n",
    "        '5': 'Indígena',\n",
    "        '9': 'Ignorado',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_raca.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_raca\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('escolaridade', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_escolaridade = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Sem instrução',\n",
    "        '2': 'Fundamental incompleto',\n",
    "        '3': 'Fundamental completa',\n",
    "        '4': 'Médio incompleto',\n",
    "        '5': 'Médio completo',\n",
    "        '6': 'Superior incompleto',\n",
    "        '7': 'Superior completo',\n",
    "        '8': 'Pós-graduação, mestrado ou doutorado',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_escolaridade.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_escolaridade\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('escolaridade', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_resposta_covid = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Sim',\n",
    "        '2': 'Não ',\n",
    "        '3': 'Não sabe',\n",
    "        '9': 'Ignorado',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_resposta_covid.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_resposta_covid\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('resposta_internado', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_resposta_internado = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Sim',\n",
    "        '2': 'Não ',\n",
    "        '3': 'Não foi atendido',\n",
    "        '9': 'Ignorado',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_resposta_internado.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_resposta_internado\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('resposta_faixa_rendimento', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_resposta_faixa_rendimento = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '00':   '0 - 100',\n",
    "        '01':\t'101 - 300',\n",
    "        '02':\t'301 - 600',\n",
    "        '03':\t'601 - 800',\n",
    "        '04':\t'801 - 1.600',\n",
    "        '05':\t'1.601 - 3.000',\n",
    "        '06':\t'3.001 - 10.000',\n",
    "        '07':\t'10.001 - 50.000',\n",
    "        '08':\t'50.001 - 100.000',\n",
    "        '09':\t'Mais de 100.000',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_resposta_faixa_rendimento.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_resposta_faixa_rendimento\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('resposta_situacao_domicilio', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_resposta_situacao_domicilio = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Próprio - já pago ',\n",
    "        '2': 'Próprio - ainda pagando',\n",
    "        '3': 'Alugado',\n",
    "        '4': 'Cedido por empregador',\n",
    "        '5': 'Cedido por familiar ',\n",
    "        '6': 'Cedido de outra forma ',\n",
    "        '7': 'Outra condição',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_resposta_situacao_domicilio.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_resposta_situacao_domicilio\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('questao', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_mapa_questoes = spark.createDataFrame(data=[{  \n",
    "    \"UF\": \"uf\"\n",
    "  , \"V1012\": \"semana_mes\"\n",
    "  , \"V1013\": \"mes\"\n",
    "  , \"V1022\": \"area_domicilio\"\n",
    "  , \"A002\": \"idade\"\n",
    "  , \"A003\": \"sexo\"\n",
    "  , \"A004\": \"cor_raca\"\n",
    "  , \"A005\": \"escolaridade\"\n",
    "  , \"B0011\": \"teve_febre\"\n",
    "  , \"B0014\": \"teve_dificuldade_respirar\"\n",
    "  , \"B0015\": \"teve_dor_cabeca\"\n",
    "  , \"B0019\": \"teve_fadiga\"\n",
    "  , \"B00111\": \"teve_perda_cheiro\"\n",
    "  , \"B002\": \"foi_posto_saude\"\n",
    "  , \"B0031\": \"ficou_em_casa\"\n",
    "  , \"B005\": \"ficou_internado\"\n",
    "  , \"B007\": \"tem_plano_saude\"\n",
    "  , \"C007B\": \"assalariado\"\n",
    "  , \"C01011\": \"faixa_rendimento\"\n",
    "  , \"F001\": \"situacao_domicilio\"\n",
    "  }], schema=_schema)\n",
    "\n",
    "_mapa_questoes.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_questoes\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema = t.StructType(\n",
    "    [\n",
    "          t.StructField('cd', t.StringType())\n",
    "        , t.StructField('sexo', t.StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "_sexo = spark.createDataFrame(data=[\n",
    "    {\n",
    "        '1': 'Masculino',\n",
    "        '2': 'Feminino',\n",
    "    }], schema=_schema)\n",
    "\n",
    "_sexo.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'refined_pnad')\\\n",
    "    .option(\"table\", \"tb_d_sexo\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trusted Data\n",
    "\n",
    "#### Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import transform\n",
    "from _spark import get_spark, _display\n",
    "\n",
    "df = spark\\\n",
    "    .read\\\n",
    "    .option('delimiter',',')\\\n",
    "    .option('header',True)\\\n",
    "    .option('inferSchema',True)\\\n",
    "    .csv('../data/raw')\n",
    "\n",
    "df = transform(df)\n",
    "\n",
    "df.write\\\n",
    "    .format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\", gcs_bucket)\\\n",
    "    .option(\"credentialsFile\",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\\\n",
    "    .option(\"project\", \"fiap-tech-challenge-3\")\\\n",
    "    .option(\"parentProject\", \"fiap-tech-challenge-3\")\\\n",
    "    .option('dataset', 'trusted_pnad')\\\n",
    "    .option(\"table\", \"tb_f_covid_2020\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
